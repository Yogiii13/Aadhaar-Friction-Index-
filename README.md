# Aadhaar Friction Index (AFI) - Complete Analysis & Visualization Platform

<p align="center">
  <img src="https://img.shields.io/badge/Hackathon-UIDAI%20Hackathon-blue?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Python-Data%20Analysis-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/Pandas-Data%20Processing-150458?style=for-the-badge&logo=pandas&logoColor=white"/>
  <img src="https://img.shields.io/badge/Jupyter-Research-F37626?style=for-the-badge&logo=jupyter&logoColor=white"/>
  <img src="https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white"/>
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge"/>
</p>


## ğŸ“Œ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Installation](#installation)
- [Usage](#usage)
  - [Jupyter Notebooks](#jupyter-notebooks)
  - [Streamlit Dashboard](#streamlit-dashboard)
- [Dashboard Guide](#dashboard-guide)
- [Key Metrics and Definitions](#key-metrics-and-definitions)
- [Data Sources](#data-sources)
- [Visualizations Generated](#visualizations-generated)
- [Output Tables](#output-tables)
- [Deployment](#deployment)
- [Customization Guide](#customization-guide)
- [Troubleshooting](#troubleshooting)
- [Complete Workflow Example](#complete-workflow-example)
- [Acknowledgments](#acknowledgments)
- [Contributing](#contributing)
- [Project Statistics](#project-statistics)
- [Contact](#contact)
- [Quick Links](#quick-links)
- [Learning Resources](#learning-resources)
- [Key Achievements](#key-achievements)
- [Use Cases](#use-cases)
- [Final Notes](#final-notes)

---

## Overview

The **Aadhaar Friction Index (AFI)** is a comprehensive data-driven analysis platform that quantifies and visualizes friction points in India's Aadhaar authentication system. It combines statistical analysis, interactive visualizations, and machine learning techniques to identify where the digital identity system creates barriers for citizens.

This project provides:
- **Quantitative friction measurement** across states and districts
- **Root cause analysis** through signal decomposition
- **Interactive dashboards** for real-time monitoring
- **Actionable insights** for policy makers and operations teams
- **Trend analysis** to track system improvements over time

### Problem Statement

Despite being one of the world's largest digital identity systems, Aadhaar faces operational challenges that create friction for users. This project makes these invisible barriers visible through data.

### Solution

A multi-layered analysis platform combining:
1. **Statistical indexing** (AFI calculation)
2. **Interactive Jupyter notebooks** for deep analysis
3. **Streamlit dashboard** for accessible insights
4. **Exportable reports** for stakeholders

---

## Key Features

### 1. **Friction Index Calculation**
- Combines 4 weighted signal components
- Normalized 0-100 scale for standardized comparison
- Covers state, district, and temporal dimensions

### 2. **Advanced Analytics**
- Demographic breakdown (age, gender impact analysis)
- Geographic comparisons (state-wise performance)
- Temporal trend analysis (month-over-month changes)
- Hidden risk detection (low volume, high friction areas)

### 3. **Interactive Visualizations**
- 8 specialized dashboard pages
- Heatmaps, scatter plots, time-series charts
- Parallel coordinates for multi-dimensional analysis
- Drill-down capabilities from state â†’ district level

### 4. **Multiple Output Formats**
- **Jupyter Notebooks** - Detailed exploratory analysis
- **Streamlit Web App** - Interactive dashboard
- **PNG/HTML** - Static & interactive charts
- **CSV/Parquet/SQLite** - Data export options
- **Excel** - Formatted tables for sharing

### 5. **Production-Ready**
- Data caching for performance
- Error handling & validation
- Automated report generation
- State filters & custom queries

---

## Project Structure

```
AADHAAR-FRICTION-INDEX/
â”‚
â”œâ”€â”€ ğŸ“‚ datasets/                          # Data layers
â”‚   â”œâ”€â”€ raw/                              # Raw Aadhaar API data
â”‚   â”‚   â”œâ”€â”€ api_data_aadhaar_biometric_*.csv       # Biometric updates
â”‚   â”‚   â”œâ”€â”€ api_data_aadhaar_demographic_*.csv     # Demographic updates
â”‚   â”‚   â””â”€â”€ api_data_aadhaar_enrolment_*.csv       # Enrollment patterns
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                        # Cleaned & normalized data
â”‚   â”‚   â”œâ”€â”€ biometric_updates_cleaned.csv
â”‚   â”‚   â”œâ”€â”€ demographic_updates_cleaned.csv
â”‚   â”‚   â””â”€â”€ enrolment_cleaned.csv
â”‚   â”‚
â”‚   â””â”€â”€ index/                            # Core AFI outputs
â”‚       â”œâ”€â”€ aadhaar_friction_index.csv
â”‚       â””â”€â”€ aadhaar_friction_index_ranked.csv
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                         # Analysis workflows
â”‚   â”œâ”€â”€ 01_exploration.ipynb              # ğŸ“Š Data exploration & validation
â”‚   â”œâ”€â”€ 02_friction_signal.ipynb          # âš™ï¸ Signal engineering
â”‚   â”œâ”€â”€ 03_aadhaar_friction_index_construction.ipynb  # ğŸ”¢ AFI computation
â”‚   â””â”€â”€ 04_visualization.ipynb            # ğŸ“ˆ Enhanced visualizations
â”‚
â”œâ”€â”€ ğŸ“‚ outputs/                           # Analysis deliverables
â”‚   â”‚
â”‚   â”œâ”€â”€ plots/                            # Visualization exports
â”‚   â”‚   â”œâ”€â”€ 01_afi_distribution_statistics.png
â”‚   â”‚   â”œâ”€â”€ 02_friction_signal_analysis.png
â”‚   â”‚   â”œâ”€â”€ 03_hidden_risk_analysis.png
â”‚   â”‚   â”œâ”€â”€ 04_state_level_analysis.png
â”‚   â”‚   â”œâ”€â”€ afi_heatmap_district_time.png
â”‚   â”‚   â”œâ”€â”€ afi_trend_selected_districts.png
â”‚   â”‚   â”œâ”€â”€ hidden_risk_scatter.png
â”‚   â”‚   â”œâ”€â”€ lifecycle_flow_imbalance.png
â”‚   â”‚   â”œâ”€â”€ interactive_01_district_scatter.html
â”‚   â”‚   â”œâ”€â”€ interactive_02_monthly_trends.html
â”‚   â”‚   â””â”€â”€ interactive_03_hidden_risk_sunburst.html
â”‚   â”‚
â”‚   â””â”€â”€ tables/                           # Analytical tables
â”‚       â”œâ”€â”€ excel/
â”‚       â”‚   â””â”€â”€ afi_analysis_tables.xlsx  # Formatted workbook
â”‚       â”‚
â”‚       â”œâ”€â”€ parquet/
â”‚       â”‚   â”œâ”€â”€ afi_summary_by_district.parquet
â”‚       â”‚   â”œâ”€â”€ afi_summary_by_state.parquet
â”‚       â”‚   â”œâ”€â”€ friction_signal_summary.parquet
â”‚       â”‚   â””â”€â”€ hidden_risk.parquet
â”‚       â”‚
â”‚       â”œâ”€â”€ sqlite/
â”‚       â”‚   â””â”€â”€ aadhaar_friction_tables.db
â”‚       â”‚
â”‚       â”œâ”€â”€ 00_summary_statistics.csv     # Key metrics
â”‚       â”œâ”€â”€ afi_summary_by_district.csv   # District AFI rankings
â”‚       â”œâ”€â”€ afi_summary_by_state.csv      # State AFI rankings
â”‚       â”œâ”€â”€ district_friction_typology.csv # Classification
â”‚       â”œâ”€â”€ friction_signal_summary.csv   # Signal breakdown
â”‚       â”œâ”€â”€ hidden_risk_table.csv         # Risk detection
â”‚       â”œâ”€â”€ lifecycle_imbalance_table.csv # Enrolment vs updates
â”‚       â”œâ”€â”€ monthly_afi_trends.csv        # Time series
â”‚       â””â”€â”€ top_100_high_friction_records.csv  # Audit data
â”‚
â”œâ”€â”€ ğŸ“‚ src/                               # Core business logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py                  # Data cleaning & normalization
â”‚   â”œâ”€â”€ signal.py                         # Signal computation (UIS, RIS, BSS, TSD)
â”‚   â”œâ”€â”€ index.py                          # AFI calculation engine
â”‚   â””â”€â”€ utils.py                          # Helpers & utilities
â”‚
â”œâ”€â”€ ğŸ“„ streamlit_app.py                   # ğŸŒ Interactive web dashboard
â”œâ”€â”€ ğŸ“„ requirements.txt                   # Python dependencies
â”œâ”€â”€ ğŸ“„ .gitignore                         # Git ignore patterns
â”œâ”€â”€ ğŸ“„ LICENSE                            # MIT License
â””â”€â”€ ğŸ“„ README.md                          # This file
```

---

## Getting Started

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Git (for cloning repository)
- ~500MB disk space
- Modern web browser (for Streamlit dashboard)

### System Requirements

- **OS**: Windows, macOS, Linux
- **Memory**: 4GB minimum (8GB recommended)
- **Processor**: Intel/AMD dual-core minimum

---

## Installation

### Step 1: Clone Repository

```bash
git clone https://github.com/Yogiii13/Aadhaar-Friction-Index-.git
cd Aadhaar-Friction-Index-
```

### Step 2: Create Virtual Environment (Recommended)

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

**requirements.txt includes:**
```
pandas==2.0.3
numpy==1.24.3
matplotlib==3.7.2
seaborn==0.12.2
plotly==5.17.0
jupyter==1.0.0
streamlit==1.28.1
openpyxl==3.1.2
pyarrow==22.0.0
sqlalchemy==2.0.20
```

### Step 4: Verify Installation

```bash
python -c "import pandas, plotly, streamlit; print('âœ“ All packages installed')"
```

---

## Usage

### Option A: Jupyter Notebooks (Deep Analysis)

#### Launch Jupyter
```bash
jupyter notebook
```

#### Run Notebooks in Sequence

**1. `01_exploration.ipynb` - Data Exploration**
```python
# Understand data structure and distributions
# Handles missing values, outliers, anomalies
# Output: Clean datasets ready for analysis
```
- Explores raw Aadhaar API data
- Validates data quality
- Creates clean datasets for next steps
- **Duration**: 10-15 minutes

**2. `02_friction_signal.ipynb` - Signal Engineering**
```python
# Calculate 4 friction signals
from src.signal import calculate_friction_signals

friction_signals = calculate_friction_signals(
    biometric_clean, 
    demographic_clean, 
    enrolment_clean
)
```
- Computes UIS (Update Intensity)
- Computes RIS (Resolution Issues)
- Computes BSS (Biometric Stress)
- Computes TSD (Temporal Deviation)
- **Duration**: 15-20 minutes

**3. `03_aadhaar_friction_index_construction.ipynb` - AFI Calculation**
```python
# Calculate final AFI score
from src.index import calculate_afi

afi_scores = calculate_afi(friction_signals)
afi_ranked = afi_scores.sort_values('AFI', ascending=False)

print(afi_ranked.head(10))  # Top 10 friction areas
```
- Combines signals with weights
- Normalizes to 0-100 scale
- Ranks by state/district
- Produces AFI tables
- **Duration**: 5-10 minutes

**4. `04_visualization.ipynb` - Enhanced Visualizations**
```python
# Create 6 sections of visualizations
# Section 1: Distribution & Statistics
# Section 2: Friction Signal Analysis
# Section 3: Hidden Risk Deep Dive
# Section 4: State-Level Analysis
# Section 5: Interactive Plotly Dashboards
# Section 6: Summary Statistics
```
- Generates PNG plots for reports
- Creates interactive HTML charts
- Produces summary statistics
- Exports all tables (CSV, Excel, Parquet, SQLite)
- **Duration**: 10-15 minutes

#### Running a Complete Analysis

```bash
# All notebooks in sequence
jupyter nbconvert --to notebook --execute 01_exploration.ipynb
jupyter nbconvert --to notebook --execute 02_friction_signal.ipynb
jupyter nbconvert --to notebook --execute 03_aadhaar_friction_index_construction.ipynb
jupyter nbconvert --to notebook --execute 04_visualization.ipynb
```

---

### Option B: Streamlit Dashboard (Interactive Exploration)

#### Launch Dashboard

```bash
streamlit run streamlit_app.py
```

**Output:**
```
  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.x.x:8501
```

#### Dashboard Pages

##### ğŸ“ˆ **Dashboard Overview**
**Purpose:** Executive summary at a glance

**Features:**
- 5 KPI cards (Avg AFI, High Friction Count, Districts, States, Hidden Risks)
- AFI distribution histogram
- Friction classification pie chart
- Top 15 high-risk districts ranked bar chart

**Best For:** Daily status checks, leadership briefings

**Interactive Elements:**
- Hover for exact values
- Click legend items to toggle
- Zoom on chart sections

---

##### ğŸ”¥ **High-Risk Districts**
**Purpose:** Identify intervention targets

**Features:**
- State filter dropdown
- Risk level selector (All/High/Medium/Low)
- Scatter plot: Avg AFI vs Max AFI
- Detailed metrics table
- Download filtered data as CSV

**Best For:** Operational planning, audit preparation

**Filters:**
- High Friction: AFI â‰¥ 70
- Medium Friction: AFI 40-70
- Low Friction: AFI < 40

---

##### âš™ï¸ **Friction Signal Analysis**
**Purpose:** Understand root causes

**Features:**
- Signal definitions (UIS, RIS, BSS, TSD)
- 4 KPI cards showing average signals
- Parallel coordinates plot
- Top UIS and BSS districts

**Best For:** Root cause analysis, technical troubleshooting

**Signals Explained:**
| Signal | Meaning | Implication |
|--------|---------|------------|
| UIS | Unresolved Issues | Problems pending resolution |
| RIS | Resolution Issues | Problems in resolution process |
| BSS | Biometric Stress | Fingerprint/iris authentication failures |
| TSD | Temporal Deviation | Time-based performance variations |

---

##### âš ï¸ **Hidden Risk Detection**
**Purpose:** Find overlooked problems

**Features:**
- Definition: Low updates but high AFI
- Scatter plot: Updates vs AFI correlation
- Update distribution histogram
- AFI distribution in hidden risks
- Top 20 hidden risk cases table

**Best For:** Audits, finding missed problems

**Key Insight:** Not all problems show as high update volume

---

##### ğŸ“‹ **State Comparison**
**Purpose:** Regional strategy planning

**Features:**
- Top states by average AFI
- Sort options (Avg/Max AFI, District count)
- Bar chart with value labels
- Scatter: Avg vs Max AFI by state
- State summary table

**Best For:** Funding allocation, policy decisions

**Insights:**
- Which states need resources
- State variation patterns
- District density vs friction

---

##### ğŸ“… **Trends & Timeline**
**Purpose:** Monitor improvement/degradation

**Features:**
- Monthly AFI average and median
- Districts reporting over time
- Lifecycle imbalance (Enrolment vs Updates)
- Update-to-Enrolment ratio trend

**Best For:** Tracking interventions, assessing progress

**Metrics:**
- â†‘ Rising AFI = Degradation
- â†“ Falling AFI = Improvement
- Ratio > 5x = Severe imbalance

---

##### ğŸ“Š **Detailed Tables**
**Purpose:** Deep dives into specific data

**Features:**
- 7 table options to choose from
- Data exploration with sorting
- Download any table as CSV
- Display up to 100 rows

**Available Tables:**
1. Top 100 High Friction Records
2. District Friction Typology
3. All Districts Summary
4. All States Summary
5. Friction Signals by District
6. Monthly Trends
7. Lifecycle Imbalance

**Best For:** Custom analysis, data validation

---

##### â„¹ï¸ **About & Methodology**
**Purpose:** Understand how it works

**Content:**
- Project overview
- AFI formula explanation
- Signal definitions
- Friction level classification
- Data sources
- Contact information

---

#### Sidebar Features

**State Filter:**
```
All States / Andhra Pradesh / Arunachal Pradesh / ... / Telangana
```

**Navigation:**
- Quick links to all 8 pages
- One-click page switching
- Active page indicator

---

## Key Metrics and Definitions

### AFI (Aadhaar Friction Index)

**Definition:** Quantitative measure (0-100) of operational friction in Aadhaar system

**Formula:**
```
AFI_raw = (0.30 Ã— UIS) + (0.25 Ã— RIS) + (0.25 Ã— BSS) + (0.20 Ã— TSD)
AFI = 100 Ã— (AFI_raw - AFI_min) / (AFI_max - AFI_min)
```

**Interpretation:**
- **0-40**: Low friction (green ğŸŸ¢)
- **40-70**: Medium friction (yellow ğŸŸ¡)
- **70-100**: High friction (red ğŸ”´)

**Time Period:** 2025-01 onwards (monthly granularity)

**Geographic Coverage:** All Indian states and districts

---

### Component Signals

#### 1. **UIS (Update Intensity Score)** - Weight: 30%

**Meaning:** How frequently users must update Aadhaar information

**Calculation:**
```
UIS = (Total Updates / Total Records) Ã— 100
```

**Implications:**
- High UIS = Users updating frequently = Problems with initial enrollment
- Low UIS = Stable records = Good data quality

**Range:** 0-100 (normalized)

---

#### 2. **RIS (Repeat Interaction Score)** - Weight: 25%

**Meaning:** Problems in the resolution/support process

**Calculation:**
```
RIS = (Failed Resolutions / Total Attempts) Ã— 100
```

**Implications:**
- High RIS = Support system struggling
- Low RIS = Issues resolved quickly

**Range:** 0-100 (normalized)

---

#### 3. **BSS (Biometric Stress Score)** - Weight: 25%

**Meaning:** Biometric authentication failures and retries

**Calculation:**
```
BSS = (Biometric Failures / Total Attempts) Ã— 100
```

**Implications:**
- High BSS = Fingerprint/iris issues (age, quality, equipment)
- Low BSS = Good biometric infrastructure

**Range:** 0-100 (normalized)

---

#### 4. **TSD (Temporal Shift Deviation)** - Weight: 20%

**Meaning:** Time-based variations in system performance

**Calculation:**
```
TSD = Std Dev of AFI across months
```

**Implications:**
- High TSD = Inconsistent performance
- Low TSD = Stable system

**Range:** 0-100 (normalized)

---

### Classification System

| Level | AFI Range | Color | Action | Duration |
|-------|-----------|-------|--------|----------|
| Low Friction | 0-40 | ğŸŸ¢ Green | Monitor | Routine |
| Medium Friction | 40-70 | ğŸŸ¡ Yellow | Review & Improve | 1-3 months |
| High Friction | 70-100 | ğŸ”´ Red | Immediate Action | <1 month |

---

### Hidden Risk Definition

**Criteria:**
- Total Updates < Median Updates (low volume)
- AFI > 75th Percentile (high friction)

**Implication:** These districts are being missed because their update volume is low, but they have serious problems

**Example:**
```
District A: 50 updates, AFI = 85 â†’ HIDDEN RISK
District B: 5000 updates, AFI = 75 â†’ VISIBLE RISK
```

---

## Data Sources

### Raw Data Origin

**Source:** UIDAI Public API
**Type:** Aggregate statistics (no PII)
**Coverage:** All 28 states + 8 union territories
**Time Period:** 2025-01 onwards
**Update Frequency:** Monthly

### Three Primary Datasets

#### 1. **Biometric Updates Data**
```csv
state, district, period, biometric_update_count, 
biometric_failure_count, biometric_retry_count, ...
```
- Fingerprint authentication data
- Iris authentication data
- Failure rates and retries
- Biometric stress indicators

#### 2. **Demographic Updates Data**
```csv
state, district, period, demographic_update_count,
address_updates, name_updates, dob_updates, ...
```
- Address changes
- Name corrections
- DOB updates
- Contact information changes

#### 3. **Enrolment Data**
```csv
state, district, period, enrolment_count,
age_group, gender, mobile_linked, ...
```
- New Aadhaar registrations
- Age/gender breakdown
- Mobile linking status
- Enrollment by location type

---

## Visualizations Generated

### Static Charts (PNG - 300 DPI)

**01_afi_distribution_statistics.png**
- 4-panel visualization
- Histogram of AFI scores
- Box plot by state (top 10)
- Friction classification pie chart
- Top 15 districts horizontal bar

**02_friction_signal_analysis.png**
- Stacked bar chart (signals by district)
- Scatter plot (UIS vs RIS)
- Shows which signals dominate

**03_hidden_risk_analysis.png**
- Scatter: Updates vs AFI
- Top hidden risk bar chart
- Update distribution histogram
- Risk by state bubble chart

**04_state_level_analysis.png**
- Top 20 states ranked bar chart
- Average vs maximum AFI scatter
- State size vs friction relationship

### Interactive Charts (HTML - Plotly)

**interactive_01_district_scatter.html**
- Explore districts interactively
- Filter by state
- Hover for details
- Click legend to toggle categories

**interactive_02_monthly_trends.html**
- Timeline of AFI changes
- Zoom into specific periods
- Compare average and median
- Download as PNG

**interactive_03_hidden_risk_sunburst.html**
- Hierarchical: State â†’ District
- Drill down into regions
- Color intensity = AFI value

### Dashboard (Web Interface)

**streamlit_app.py**
- 8 interactive pages
- Real-time filtering
- State-level analysis
- Download capabilities
- Mobile responsive

---

## Output Tables

### CSV Format

All tables available in `outputs/tables/` as CSV for easy import

**Key Files:**

| File | Rows | Purpose |
|------|------|---------|
| afi_summary_by_district.csv | 1000+ | District rankings |
| afi_summary_by_state.csv | 48 | State comparisons |
| friction_signal_summary.csv | 1000+ | Signal breakdown |
| hidden_risk_table.csv | 100-500 | Risk detection |
| monthly_afi_trends.csv | 12-24 | Time series |
| top_100_high_friction_records.csv | 100 | Audit data |

### Excel Format

**afi_analysis_tables.xlsx** - Multi-sheet workbook
- Sheet 1: AFI by District
- Sheet 2: AFI by State
- Sheet 3: Friction Signals
- Sheet 4: Hidden Risk Districts

### Database Formats

**Parquet** (Fast, compressed)
- Column-based storage
- Efficient for analytics
- Python/R friendly

**SQLite** (Queryable)
```sql
SELECT * FROM afi_by_district WHERE avg_afi > 70;
SELECT state, AVG(avg_afi) FROM afi_by_district GROUP BY state;
```

---

## Deployment

### Local Deployment

```bash
# Development
streamlit run streamlit_app.py

# Production
streamlit run streamlit_app.py \
  --server.port 80 \
  --server.address 0.0.0.0 \
  --logger.level=error
```

### Streamlit Cloud (Free)

```bash
# 1. Push to GitHub
git push origin main

# 2. Connect repo at https://streamlit.io/cloud
# 3. Dashboard goes live automatically
```

### Heroku

```bash
# Create Procfile
echo "web: streamlit run streamlit_app.py" > Procfile

# Deploy
heroku create your-app-name
git push heroku main
```

### AWS EC2

```bash
# 1. Launch Ubuntu instance
# 2. Install Python & dependencies
sudo apt-get install python3 python3-pip
pip3 install -r requirements.txt

# 3. Run Streamlit
streamlit run streamlit_app.py --server.port 80 --server.address 0.0.0.0
```

### Docker

```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["streamlit", "run", "streamlit_app.py"]
```

```bash
docker build -t afi-dashboard .
docker run -p 8501:8501 afi-dashboard
```

---

## Customization Guide

### Modify Friction Thresholds

**File:** `streamlit_app.py`

```python
def classify_friction(afi):
    """Customize these values"""
    if afi >= 75:      # Was 70
        return "ğŸ”´ High Friction"
    elif afi >= 45:    # Was 40
        return "ğŸŸ¡ Medium Friction"
    else:
        return "ğŸŸ¢ Low Friction"
```

### Change AFI Weights

**File:** `src/index.py`

```python
def calculate_afi(signals):
    # Current weights
    weights = {
        'UIS': 0.30,  # Change here
        'RIS': 0.25,
        'BSS': 0.25,
        'TSD': 0.20
    }
    # Must sum to 1.0
```

### Add New Visualizations

**File:** `streamlit_app.py`

```python
elif page == "ğŸ†• New Page":
    st.markdown("## New Analysis")
    
    # Your plotly/matplotlib code here
    fig = px.scatter(data, x='col1', y='col2')
    st.plotly_chart(fig, use_container_width=True)
```

### Modify Color Scheme

**File:** `streamlit_app.py`

```python
# Current colors
COLOR_HIGH = '#ef4444'      # Red
COLOR_MEDIUM = '#f59e0b'    # Orange
COLOR_LOW = '#10b981'       # Green

# Change to custom palette
COLOR_HIGH = '#8B0000'      # Dark red
COLOR_MEDIUM = '#FFD700'    # Gold
COLOR_LOW = '#006400'       # Dark green
```

---

## Troubleshooting

### Problem: Data Files Not Found

**Error:**
```
FileNotFoundError: outputs/tables/afi_summary_by_district.csv
```

**Solution:**
```bash
# Check path structure
ls -la outputs/tables/

# Ensure you've run all notebooks first
jupyter notebook 04_visualization.ipynb
```

### Problem: Charts Not Displaying

**Error:**
```
ModuleNotFoundError: No module named 'plotly'
```

**Solution:**
```bash
pip install --upgrade plotly
pip install kaleido  # For static chart exports
```

### Problem: Port Already in Use

**Error:**
```
Address already in use
```

**Solution:**
```bash
# Use different port
streamlit run streamlit_app.py --server.port 8502

# Or kill process
# Windows
netstat -ano | findstr :8501
taskkill /PID <PID> /F

# Linux/Mac
lsof -i :8501
kill -9 <PID>
```

### Problem: Slow Performance

**Solutions:**
```python
# Increase cache timeout
@st.cache_data(ttl=3600)  # 1 hour
def load_data():
    ...

# Reduce data size
filtered_df = df.sample(frac=0.1)  # Use 10%

# Enable profiler
streamlit run streamlit_app.py --logger.level=debug
```

### Problem: Memory Error

**Solutions:**
```bash
# Increase Python memory
export PYTHONUNBUFFERED=1
python -Xmx4G streamlit_app.py

# Process data in chunks
for chunk in pd.read_csv('large_file.csv', chunksize=10000):
    process_chunk(chunk)
```

---

## Complete Workflow Example

### Scenario: Analyze and Present High-Risk Districts

**Step 1: Run Analysis Notebooks**
```bash
jupyter notebook 04_visualization.ipynb
# Runs all visualizations, exports tables
# Duration: ~30 minutes
```

**Step 2: Open Dashboard**
```bash
streamlit run streamlit_app.py
```

**Step 3: Filter High-Risk Districts**
1. Navigate to "ğŸ”¥ High-Risk Districts" page
2. Select state from sidebar
3. Choose "High Friction (â‰¥70)" filter
4. View scatter plot and data table

**Step 4: Export Report**
```
Click "ğŸ“¥ Download as CSV"
â†’ Saves filtered_districts_[state].csv
```

**Step 5: Analyze Root Causes**
1. Go to "âš™ï¸ Friction Signal Analysis"
2. Same state filter
3. Review UIS, RIS, BSS, TSD breakdown
4. Identify primary problem drivers

**Step 6: Check for Hidden Risks**
1. Go to "âš ï¸ Hidden Risk Detection"
2. Review scatter plot
3. Top 20 hidden risk cases
4. Note overlooked problems

**Step 7: Generate Report**
```python
# Export summary
state_data.to_excel('report.xlsx', index=False)
# Include screenshots from dashboard
```

---
## Acknowledgments

### Contributors & Support
- **UIDAI** - Public API access
- **Data Contributors** - Providing anonymized datasets
- **Community Members** - Feedback and suggestions
- **Open Source Community** - Libraries and tools

### Libraries Used
- **Pandas** - Data manipulation
- **Plotly** - Interactive visualizations
- **Streamlit** - Web framework
- **Matplotlib/Seaborn** - Static charts
- **Jupyter** - Interactive notebooks
- **NumPy** - Numerical computing

---

## Contributing

### How to Contribute

We welcome contributions! Please follow these steps:

#### 1. Fork the Repository
```bash
git clone https://github.com/YOUR_USERNAME/Aadhaar-Friction-Index-.git
cd Aadhaar-Friction-Index-
```

#### 2. Create Feature Branch
```bash
git checkout -b feature/your-feature-name
```

#### 3. Make Changes
- Add features, fix bugs, improve docs
- Follow PEP 8 style guide
- Add docstrings to functions
- Write unit tests for new code

#### 4. Commit & Push
```bash
git add .
git commit -m "Add: Brief description of changes"
git push origin feature/your-feature-name
```

#### 5. Create Pull Request
- Go to GitHub
- Create PR with detailed description
- Link related issues
- Wait for review

### Contribution Areas

**High Priority:**
- [ ] Add more signal types
- [ ] Implement predictive modeling
- [ ] Improve performance optimization
- [ ] Add export to Power BI/Tableau

**Medium Priority:**
- [ ] Better error handling
- [ ] Additional visualizations
- [ ] Mobile app version
- [ ] Multi-language support

**Documentation:**
- [ ] Expand methodology docs
- [ ] Add video tutorials
- [ ] Create use case examples
- [ ] Translate to regional languages

---
## Project Statistics

| Metric | Value |
|--------|-------|
| Lines of Code | 3000+ |
| Notebooks | 4 |
| Dashboard Pages | 8 |
| Visualizations | 15+ |
| CSV Tables | 8 |
| Data Points | 500,000+ |
| States Covered | 28 + 8 UT |
| Districts Covered | 700+ |
| Time Series Months | 12+ |

---

## Contact

### Getting Help

**Community:**
- ğŸ’¬ [GitHub Discussions](https://github.com/Yogiii13/Aadhaar-Friction-Index-/discussions)
- ğŸ› [Issue Tracker](https://github.com/Yogiii13/Aadhaar-Friction-Index-/issues)

**Contact:**
- ğŸ‘¤ Project Lead: [@Yogiii13](https://github.com/Yogiii13)
- ğŸ‘¤ Contributor: [@Sojwal27](https://github.com/sojwal27)
- ğŸ“§ Email: [yogeshyadav14434@gmail.com]

### Report a Bug

**Use Issue Template:**
```markdown
**Description:**
Brief description of what's wrong

**Steps to Reproduce:**
1. Step one
2. Step two
3. Step three

**Expected Behavior:**
What should happen

**Actual Behavior:**
What actually happens

**Environment:**
- Python version
- OS
- Installed packages
```

---
## Quick Links

| Resource | Link |
|----------|------|
| **GitHub Repository** | [Aadhaar-Friction-Index-](https://github.com/Yogiii13/Aadhaar-Friction-Index-) |
| **Issue Tracker** | [Report Issues](https://github.com/Yogiii13/Aadhaar-Friction-Index-/issues) |
| **Discussions** | [Ask Questions](https://github.com/Yogiii13/Aadhaar-Friction-Index-/discussions) |
| **Main Author** | [@Yogiii13](https://github.com/Yogiii13) |
| **License** | [MIT License](LICENSE) |

---
## Learning Resources

### For Beginners
1. Read this README
2. Watch dashboard tour (docs/TOUR.md)
3. Explore Dashboard Overview page
4. Review sample CSV files

### For Analysts
1. Run 04_visualization.ipynb
2. Study friction signal definitions
3. Explore hidden risk detection
4. Review state comparison analysis

### For Developers
1. Review src/ module structure
2. Study signal.py calculation logic
3. Examine index.py AFI formula
4. Check utils.py helper functions

### For Data Scientists
1. Review 02_friction_signal.ipynb
2. Study feature engineering approach
3. Modify weights in index.py
4. Add new signal components

---

## Key Achievements

- âœ… Analyzed 500,000+ Aadhaar records
- âœ… Covered 700+ districts across India
- âœ… Identified 100+ hidden risk cases
- âœ… Created 8-page interactive dashboard
- âœ… Generated 15+ publication-ready visualizations
- âœ… Documented complete methodology
- âœ… Enabled stakeholder insights

---

## Use Cases

### For Government Agencies
- Identify districts needing support
- Allocate resources efficiently
- Monitor system performance
- Track improvement initiatives

### For Researchers
- Study digital identity barriers
- Analyze demographic disparities
- Predict failure patterns
- Benchmark system performance

### For Policy Makers
- Evidence-based decision making
- Regional prioritization
- Budget allocation justification
- Progress monitoring

### For Citizens
- Understand where problems occur
- Advocate for improvements
- Participate in feedback
- Track system evolution

---

## Final Notes

**Thank you** for using the Aadhaar Friction Index project!

This tool was created to make invisible barriers visible and empower data-driven decisions about India's digital identity system.

**We'd love your feedback!** Please:
- â­ Star this repository
- ğŸ’¬ Share your insights
- ğŸ› Report bugs
- ğŸ Contribute improvements
- ğŸ“£ Spread the word

---
**Made with â¤ï¸ for a more transparent and accessible digital India**

